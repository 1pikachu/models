apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  name: $(WORKFLOW_NAME)
spec:
  entrypoint: $(MODEL_NAME)
  templates:
  - name: $(MODEL_NAME)
    steps:
    - - name: train-wide-deep-large-ds
        template: train-wide-deep-large-ds
    - - name: wide-deep-large-ds-deployment
        template: wide-deep-large-ds-deployment
    - - name: wide-deep-large-ds-service
        template: wide-deep-large-ds-service
  - name: train-wide-deep-large-ds
    container:
      image: $(REGISTRY)/model-zoo:2.1.0-recommendation-$(MODEL_NAME)
      command: [$(MODEL_DIR)/quickstart/$(MODEL_SCRIPT)]
      securityContext:
        runAsUser: $(USER_ID)
        runAsGroup: $(GROUP_ID)
        fsGroup: $(GROUP_ID)
      envFrom:
      - configMapRef:
          name: mlops-env
      env:
      # Serving requires a model base directory and a model name folder, so
      # we can't write the saved model directly into the OUTPUT_DIR, we need
      # to have a folder with the model name inside of that
      - name: OUTPUT_DIR
        value: $(OUTPUT_DIR)/$(MODEL_NAME)
      volumeMounts:
      - name: datasets
        mountPath: $(DATASET_DIR)
        readOnly: true
      - name: users
        mountPath: $(NFS_MOUNT_PATH)
    volumes:
    - name: users
      persistentVolumeClaim:
        claimName: users-pvc
    - name: datasets
      persistentVolumeClaim:
        claimName: datasets-pvc
  - name: wide-deep-large-ds-deployment
    resource:
      action: create
      manifest: |
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: $(MODEL_NAME)-deployment
          ownerReferences:
          - apiVersion: argoproj.io/v1alpha1
            kind: Workflow
            blockOwnerDeletion: true
            name: "{{workflow.name}}"
            uid: "{{workflow.uid}}"
        spec:
          selector:
            matchLabels:
              app: $(MODEL_NAME)-server
          replicas: $(REPLICAS)
          template:
            metadata:
              labels:
                app: $(MODEL_NAME)-server
            spec:
              containers:
              - name: $(MODEL_NAME)-server
                image: intel/intel-optimized-tensorflow-serving:2.2.0
                securityContext:
                  runAsUser: $(USER_ID)
                  runAsGroup: $(GROUP_ID)
                env:
                - name: MODEL_BASE_PATH
                  value: $(OUTPUT_DIR)
                - name: TF_CPP_MIN_VLOG_LEVEL
                  value: "1"
                envFrom:
                - configMapRef:
                    name: mlops-env
                volumeMounts:
                - name: users
                  mountPath: $(NFS_MOUNT_PATH)
                ports:
                - containerPort: $(TF_SERVING_PORT)
              volumes:
              - name: users
                persistentVolumeClaim:
                  claimName: users-pvc
  - name: wide-deep-large-ds-service
    resource:
      action: create
      manifest: |
        apiVersion: v1
        kind: Service
        metadata:
          name: $(MODEL_NAME)-service
          labels:
            app: $(MODEL_NAME)-server
          ownerReferences:
          - apiVersion: argoproj.io/v1alpha1
            kind: Workflow
            blockOwnerDeletion: true
            name: "{{workflow.name}}"
            uid: "{{workflow.uid}}"
        spec:
          # comment or delete the following line if you want to use a LoadBalancer
          type: NodePort
          # if your cluster supports it, uncomment the following to automatically create
          # an external load-balanced IP for the frontend service.
          # type: LoadBalancer
          ports:
          - protocol: TCP
            port: 8501
            targetPort: 8500
          selector:
            app: $(MODEL_NAME)-server
