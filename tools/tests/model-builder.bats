
setup()
{
  COMMANDS="$(model-builder commands)"
  MODELS_ALL="$(model-builder models)"
}

teardown()
{
  MODELS=()
}

last_built()
{
  local _image _created _os=$(uname -s)
  _image=$(docker images | grep $1 | head -1 | awk '{printf("%s:%s\n", $1, $2)}')
  _created="$(docker inspect $_image --format '{{.Created}}' | sed 's/T/ /g' | sed 's/\.[0-9]*Z$//')"
  case "$_os" in
    Darwin)
      echo $(( $(date +%s) - $(date -juf'%Y-%m-%d %H:%M:%S' "$_created" +%s) ))
      ;;
    Linux)
      echo $(( $(date +%s) - $(date --utc --date="$_created" '+%s') ))
      ;;
  esac
}

last_modified()
{
  local _os=$(uname -s)
  case "$_os" in
    Darwin)
      echo $(( $(date +%s) - $(stat -f%c $1) ))
      ;;
    Linux)
      expr $(date +%s) - $(stat -c %Y $1)
      ;;
  esac
}

@test "validate 'model-builder commands'" {
  run model-builder commands
  (( $status == 0 ))
  [[ $output == $COMMANDS ]]
}


@test "validate 'model-builder models'" {
  run model-builder models
  (( $status == 0 ))
  [[ $output == $MODELS_ALL ]]
}

#
# DO NOT EDIT BELOW THIS LINE - generated by model-builder-test-suite-generator Tue Nov 3 11:56:56 PST 2020
# *** tests for generate-documentation ***
#

@test "validate generate-documentation for 3d-unet-fp32-inference creates quickstart/image_segmentation/tensorflow/3d_unet/inference/fp32/README.md" {
      run model-builder generate-documentation 3d-unet-fp32-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/image_segmentation/tensorflow/3d_unet/inference/fp32/README.md) <= 50 ))
    }
@test "validate generate-documentation for bert-large-bfloat16-inference creates quickstart/language_modeling/tensorflow/bert_large/inference/bfloat16/README.md" {
      run model-builder generate-documentation bert-large-bfloat16-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/language_modeling/tensorflow/bert_large/inference/bfloat16/README.md) <= 50 ))
    }
@test "validate generate-documentation for bert-large-fp32-inference creates quickstart/language_modeling/tensorflow/bert_large/inference/fp32/README.md" {
      run model-builder generate-documentation bert-large-fp32-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/language_modeling/tensorflow/bert_large/inference/fp32/README.md) <= 50 ))
    }
@test "validate generate-documentation for bert-large-fp32-training creates quickstart/language_modeling/tensorflow/bert_large/training/fp32/README.md" {
      run model-builder generate-documentation bert-large-fp32-training
      (( $status == 0 ))
      (( $(last_modified quickstart/language_modeling/tensorflow/bert_large/training/fp32/README.md) <= 50 ))
    }
@test "validate generate-documentation for faster-rcnn-fp32-inference creates quickstart/object_detection/tensorflow/faster_rcnn/inference/fp32/README.md" {
      run model-builder generate-documentation faster-rcnn-fp32-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/object_detection/tensorflow/faster_rcnn/inference/fp32/README.md) <= 50 ))
    }
@test "validate generate-documentation for faster-rcnn-int8-inference creates quickstart/object_detection/tensorflow/faster_rcnn/inference/int8/README.md" {
      run model-builder generate-documentation faster-rcnn-int8-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/object_detection/tensorflow/faster_rcnn/inference/int8/README.md) <= 50 ))
    }
@test "validate generate-documentation for inceptionv3-fp32-inference creates quickstart/image_recognition/tensorflow/inceptionv3/inference/fp32/README.md" {
      run model-builder generate-documentation inceptionv3-fp32-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/image_recognition/tensorflow/inceptionv3/inference/fp32/README.md) <= 50 ))
    }
@test "validate generate-documentation for inceptionv3-int8-inference creates quickstart/image_recognition/tensorflow/inceptionv3/inference/int8/README.md" {
      run model-builder generate-documentation inceptionv3-int8-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/image_recognition/tensorflow/inceptionv3/inference/int8/README.md) <= 50 ))
    }
@test "validate generate-documentation for maskrcnn-fp32-inference creates quickstart/image_segmentation/tensorflow/maskrcnn/inference/fp32/README.md" {
      run model-builder generate-documentation maskrcnn-fp32-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/image_segmentation/tensorflow/maskrcnn/inference/fp32/README.md) <= 50 ))
    }
@test "validate generate-documentation for mobilenet-v1-fp32-inference creates quickstart/image_recognition/tensorflow/mobilenet_v1/inference/fp32/README.md" {
      run model-builder generate-documentation mobilenet-v1-fp32-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/image_recognition/tensorflow/mobilenet_v1/inference/fp32/README.md) <= 50 ))
    }
@test "validate generate-documentation for mobilenet-v1-int8-inference creates quickstart/image_recognition/tensorflow/mobilenet_v1/inference/int8/README.md" {
      run model-builder generate-documentation mobilenet-v1-int8-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/image_recognition/tensorflow/mobilenet_v1/inference/int8/README.md) <= 50 ))
    }
@test "validate generate-documentation for ncf-fp32-inference creates quickstart/recommendation/tensorflow/ncf/inference/fp32/README.md" {
      run model-builder generate-documentation ncf-fp32-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/recommendation/tensorflow/ncf/inference/fp32/README.md) <= 50 ))
    }
@test "validate generate-documentation for object-detection creates /README.md" {
      run model-builder generate-documentation object-detection
      (( $status == 0 ))
      (( $(last_modified /README.md) <= 50 ))
    }
@test "validate generate-documentation for preprocess-coco-val creates /README.md" {
      run model-builder generate-documentation preprocess-coco-val
      (( $status == 0 ))
      (( $(last_modified /README.md) <= 50 ))
    }
@test "validate generate-documentation for resnet50-fp32-inference creates quickstart/image_recognition/tensorflow/resnet50/inference/fp32/README.md" {
      run model-builder generate-documentation resnet50-fp32-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/image_recognition/tensorflow/resnet50/inference/fp32/README.md) <= 50 ))
    }
@test "validate generate-documentation for resnet50-int8-inference creates quickstart/image_recognition/tensorflow/resnet50/inference/int8/README.md" {
      run model-builder generate-documentation resnet50-int8-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/image_recognition/tensorflow/resnet50/inference/int8/README.md) <= 50 ))
    }
@test "validate generate-documentation for resnet50v1-5-bfloat16-inference creates quickstart/image_recognition/tensorflow/resnet50v1_5/inference/bfloat16/README.md" {
      run model-builder generate-documentation resnet50v1-5-bfloat16-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/image_recognition/tensorflow/resnet50v1_5/inference/bfloat16/README.md) <= 50 ))
    }
@test "validate generate-documentation for resnet50v1-5-fp32-inference creates quickstart/image_recognition/tensorflow/resnet50v1_5/inference/fp32/README.md" {
      run model-builder generate-documentation resnet50v1-5-fp32-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/image_recognition/tensorflow/resnet50v1_5/inference/fp32/README.md) <= 50 ))
    }
@test "validate generate-documentation for resnet50v1-5-fp32-training creates quickstart/image_recognition/tensorflow/resnet50v1_5/training/fp32/README.md" {
      run model-builder generate-documentation resnet50v1-5-fp32-training
      (( $status == 0 ))
      (( $(last_modified quickstart/image_recognition/tensorflow/resnet50v1_5/training/fp32/README.md) <= 50 ))
    }
@test "validate generate-documentation for resnet50v1-5-int8-inference creates quickstart/image_recognition/tensorflow/resnet50v1_5/inference/int8/README.md" {
      run model-builder generate-documentation resnet50v1-5-int8-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/image_recognition/tensorflow/resnet50v1_5/inference/int8/README.md) <= 50 ))
    }
@test "validate generate-documentation for rfcn-fp32-inference creates quickstart/object_detection/tensorflow/rfcn/inference/fp32/README.md" {
      run model-builder generate-documentation rfcn-fp32-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/object_detection/tensorflow/rfcn/inference/fp32/README.md) <= 50 ))
    }
@test "validate generate-documentation for scikit-learn creates /README.md" {
      run model-builder generate-documentation scikit-learn
      (( $status == 0 ))
      (( $(last_modified /README.md) <= 50 ))
    }
@test "validate generate-documentation for scikit-learn-census creates /README.md" {
      run model-builder generate-documentation scikit-learn-census
      (( $status == 0 ))
      (( $(last_modified /README.md) <= 50 ))
    }
@test "validate generate-documentation for ssd-mobilenet-fp32-inference creates quickstart/object_detection/tensorflow/ssd-mobilenet/inference/fp32/README.md" {
      run model-builder generate-documentation ssd-mobilenet-fp32-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/object_detection/tensorflow/ssd-mobilenet/inference/fp32/README.md) <= 50 ))
    }
@test "validate generate-documentation for ssd-resnet34-fp32-inference creates quickstart/object_detection/tensorflow/ssd-resnet34/inference/fp32/README.md" {
      run model-builder generate-documentation ssd-resnet34-fp32-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/object_detection/tensorflow/ssd-resnet34/inference/fp32/README.md) <= 50 ))
    }
@test "validate generate-documentation for ssd-resnet34-int8-inference creates quickstart/object_detection/tensorflow/ssd-resnet34/inference/int8/README.md" {
      run model-builder generate-documentation ssd-resnet34-int8-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/object_detection/tensorflow/ssd-resnet34/inference/int8/README.md) <= 50 ))
    }
@test "validate generate-documentation for transformer-lt-official-fp32-inference creates quickstart/language_translation/tensorflow/transformer_lt_official/inference/fp32/README.md" {
      run model-builder generate-documentation transformer-lt-official-fp32-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/language_translation/tensorflow/transformer_lt_official/inference/fp32/README.md) <= 50 ))
    }
@test "validate generate-documentation for unet-fp32-inference creates quickstart/image_segmentation/tensorflow/unet/inference/fp32/README.md" {
      run model-builder generate-documentation unet-fp32-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/image_segmentation/tensorflow/unet/inference/fp32/README.md) <= 50 ))
    }
@test "validate generate-documentation for wavenet-fp32-inference creates quickstart/text_to_speech/tensorflow/wavenet/inference/fp32/README.md" {
      run model-builder generate-documentation wavenet-fp32-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/text_to_speech/tensorflow/wavenet/inference/fp32/README.md) <= 50 ))
    }
@test "validate generate-documentation for wide-deep-fp32-inference creates quickstart/recommendation/tensorflow/wide_deep/inference/fp32/README.md" {
      run model-builder generate-documentation wide-deep-fp32-inference
      (( $status == 0 ))
      (( $(last_modified quickstart/recommendation/tensorflow/wide_deep/inference/fp32/README.md) <= 50 ))
    }
@test "validate generate-documentation for wide-deep-large-ds-fp32-training creates quickstart/recommendation/tensorflow/wide_deep_large_ds/training/fp32/README.md" {
      run model-builder generate-documentation wide-deep-large-ds-fp32-training
      (( $status == 0 ))
      (( $(last_modified quickstart/recommendation/tensorflow/wide_deep_large_ds/training/fp32/README.md) <= 50 ))
    }
@test "validate generate-documentation for xgboost creates /README.md" {
      run model-builder generate-documentation xgboost
      (( $status == 0 ))
      (( $(last_modified /README.md) <= 50 ))
    }

#
# *** tests for generate-dockerfile ***
#

@test "validate generate-dockerfile for 3d-unet-fp32-inference creates intel-tf-image-segmentation-3d-unet-fp32-inference.Dockerfile" {
    run model-builder generate-dockerfile 3d-unet-fp32-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-image-segmentation-3d-unet-fp32-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-image-segmentation-3d-unet-fp32-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for bert-large-bfloat16-inference creates intel-tf-language-modeling-bert-large-bfloat16-inference.Dockerfile" {
    run model-builder generate-dockerfile bert-large-bfloat16-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-language-modeling-bert-large-bfloat16-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-language-modeling-bert-large-bfloat16-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for bert-large-fp32-inference creates intel-tf-language-modeling-bert-large-fp32-inference.Dockerfile" {
    run model-builder generate-dockerfile bert-large-fp32-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-language-modeling-bert-large-fp32-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-language-modeling-bert-large-fp32-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for bert-large-fp32-training creates intel-tf-language-modeling-bert-large-fp32-training.Dockerfile" {
    run model-builder generate-dockerfile bert-large-fp32-training
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-language-modeling-bert-large-fp32-training.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-language-modeling-bert-large-fp32-training.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for faster-rcnn-fp32-inference creates intel-tf-object-detection-faster-rcnn-fp32-inference.Dockerfile" {
    run model-builder generate-dockerfile faster-rcnn-fp32-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-object-detection-faster-rcnn-fp32-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-object-detection-faster-rcnn-fp32-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for faster-rcnn-int8-inference creates intel-tf-object-detection-faster-rcnn-int8-inference.Dockerfile" {
    run model-builder generate-dockerfile faster-rcnn-int8-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-object-detection-faster-rcnn-int8-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-object-detection-faster-rcnn-int8-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for inceptionv3-fp32-inference creates intel-tf-image-recognition-inceptionv3-fp32-inference.Dockerfile" {
    run model-builder generate-dockerfile inceptionv3-fp32-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-image-recognition-inceptionv3-fp32-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-image-recognition-inceptionv3-fp32-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for inceptionv3-int8-inference creates intel-tf-image-recognition-inceptionv3-int8-inference.Dockerfile" {
    run model-builder generate-dockerfile inceptionv3-int8-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-image-recognition-inceptionv3-int8-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-image-recognition-inceptionv3-int8-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for maskrcnn-fp32-inference creates intel-tf-image-segmentation-maskrcnn-fp32-inference.Dockerfile" {
    run model-builder generate-dockerfile maskrcnn-fp32-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-image-segmentation-maskrcnn-fp32-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-image-segmentation-maskrcnn-fp32-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for mobilenet-v1-fp32-inference creates intel-tf-image-recognition-mobilenet-v1-fp32-inference.Dockerfile" {
    run model-builder generate-dockerfile mobilenet-v1-fp32-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-image-recognition-mobilenet-v1-fp32-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-image-recognition-mobilenet-v1-fp32-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for mobilenet-v1-int8-inference creates intel-tf-image-recognition-mobilenet-v1-int8-inference.Dockerfile" {
    run model-builder generate-dockerfile mobilenet-v1-int8-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-image-recognition-mobilenet-v1-int8-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-image-recognition-mobilenet-v1-int8-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for ncf-fp32-inference creates intel-tf-recommendation-ncf-fp32-inference.Dockerfile" {
    run model-builder generate-dockerfile ncf-fp32-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-recommendation-ncf-fp32-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-recommendation-ncf-fp32-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for object-detection creates intel-tf-object-detection.Dockerfile" {
    run model-builder generate-dockerfile object-detection
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-object-detection.Dockerfile ]]
    (( $(last_modified dockerfiles/intel-tf-object-detection.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for preprocess-coco-val creates intel-tf-object-detection-preprocess-coco-val.Dockerfile" {
    run model-builder generate-dockerfile preprocess-coco-val
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-object-detection-preprocess-coco-val.Dockerfile ]]
    (( $(last_modified dockerfiles/dataset_containers/intel-tf-object-detection-preprocess-coco-val.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for resnet50-fp32-inference creates intel-tf-image-recognition-resnet50-fp32-inference.Dockerfile" {
    run model-builder generate-dockerfile resnet50-fp32-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-image-recognition-resnet50-fp32-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-image-recognition-resnet50-fp32-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for resnet50-int8-inference creates intel-tf-image-recognition-resnet50-int8-inference.Dockerfile" {
    run model-builder generate-dockerfile resnet50-int8-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-image-recognition-resnet50-int8-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-image-recognition-resnet50-int8-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for resnet50v1-5-bfloat16-inference creates intel-tf-image-recognition-resnet50v1-5-bfloat16-inference.Dockerfile" {
    run model-builder generate-dockerfile resnet50v1-5-bfloat16-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-image-recognition-resnet50v1-5-bfloat16-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-image-recognition-resnet50v1-5-bfloat16-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for resnet50v1-5-fp32-inference creates intel-tf-image-recognition-resnet50v1-5-fp32-inference.Dockerfile" {
    run model-builder generate-dockerfile resnet50v1-5-fp32-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-image-recognition-resnet50v1-5-fp32-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-image-recognition-resnet50v1-5-fp32-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for resnet50v1-5-fp32-training creates intel-tf-image-recognition-resnet50v1-5-fp32-training.Dockerfile" {
    run model-builder generate-dockerfile resnet50v1-5-fp32-training
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-image-recognition-resnet50v1-5-fp32-training.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-image-recognition-resnet50v1-5-fp32-training.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for resnet50v1-5-int8-inference creates intel-tf-image-recognition-resnet50v1-5-int8-inference.Dockerfile" {
    run model-builder generate-dockerfile resnet50v1-5-int8-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-image-recognition-resnet50v1-5-int8-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-image-recognition-resnet50v1-5-int8-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for rfcn-fp32-inference creates intel-tf-object-detection-rfcn-fp32-inference.Dockerfile" {
    run model-builder generate-dockerfile rfcn-fp32-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-object-detection-rfcn-fp32-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-object-detection-rfcn-fp32-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for scikit-learn creates scikit-learn.Dockerfile" {
    run model-builder generate-dockerfile scikit-learn
    (( $status == 0 ))
    [[ "${lines[@]}" =~ scikit-learn.Dockerfile ]]
    (( $(last_modified dockerfiles/ml/scikit-learn/scikit-learn.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for scikit-learn-census creates scikit-learn-census.Dockerfile" {
    run model-builder generate-dockerfile scikit-learn-census
    (( $status == 0 ))
    [[ "${lines[@]}" =~ scikit-learn-census.Dockerfile ]]
    (( $(last_modified dockerfiles/ml/scikit-learn/scikit-learn-census.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for ssd-mobilenet-fp32-inference creates intel-tf-object-detection-ssd-mobilenet-fp32-inference.Dockerfile" {
    run model-builder generate-dockerfile ssd-mobilenet-fp32-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-object-detection-ssd-mobilenet-fp32-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-object-detection-ssd-mobilenet-fp32-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for ssd-resnet34-fp32-inference creates intel-tf-object-detection-ssd-resnet34-fp32-inference.Dockerfile" {
    run model-builder generate-dockerfile ssd-resnet34-fp32-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-object-detection-ssd-resnet34-fp32-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-object-detection-ssd-resnet34-fp32-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for ssd-resnet34-int8-inference creates intel-tf-object-detection-ssd-resnet34-int8-inference.Dockerfile" {
    run model-builder generate-dockerfile ssd-resnet34-int8-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-object-detection-ssd-resnet34-int8-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-object-detection-ssd-resnet34-int8-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for transformer-lt-official-fp32-inference creates intel-tf-language-translation-transformer-lt-official-fp32-inference.Dockerfile" {
    run model-builder generate-dockerfile transformer-lt-official-fp32-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-language-translation-transformer-lt-official-fp32-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-language-translation-transformer-lt-official-fp32-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for unet-fp32-inference creates intel-tf-image-segmentation-3d-unet-fp32-inference.Dockerfile" {
    run model-builder generate-dockerfile unet-fp32-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-image-segmentation-3d-unet-fp32-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-image-segmentation-unet-fp32-inference.Dockerfile dockerfiles/model_containers/intel-tf-image-segmentation-3d-unet-fp32-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for wavenet-fp32-inference creates intel-tf-text-to-speech-wavenet-fp32-inference.Dockerfile" {
    run model-builder generate-dockerfile wavenet-fp32-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-text-to-speech-wavenet-fp32-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-text-to-speech-wavenet-fp32-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for wide-deep-fp32-inference creates intel-tf-recommendation-wide-deep-fp32-inference.Dockerfile" {
    run model-builder generate-dockerfile wide-deep-fp32-inference
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-recommendation-wide-deep-fp32-inference.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-recommendation-wide-deep-fp32-inference.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for wide-deep-large-ds-fp32-training creates intel-tf-recommendation-wide-deep-large-ds-fp32-training.Dockerfile" {
    run model-builder generate-dockerfile wide-deep-large-ds-fp32-training
    (( $status == 0 ))
    [[ "${lines[@]}" =~ intel-tf-recommendation-wide-deep-large-ds-fp32-training.Dockerfile ]]
    (( $(last_modified dockerfiles/model_containers/intel-tf-recommendation-wide-deep-large-ds-fp32-training.Dockerfile) <= 50 ))
  }
@test "validate generate-dockerfile for xgboost creates xgboost.Dockerfile" {
    run model-builder generate-dockerfile xgboost
    (( $status == 0 ))
    [[ "${lines[@]}" =~ xgboost.Dockerfile ]]
    (( $(last_modified dockerfiles/ml/XGBoost/xgboost.Dockerfile) <= 50 ))
  }

#
# *** tests for package ***
#

@test "validate package for 3d-unet-fp32-inference creates 3d-unet-fp32-inference.tar.gz" {
      run model-builder package 3d-unet-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ 3d-unet-fp32-inference.tar.gz ]]
      (( $(last_modified output/3d-unet-fp32-inference.tar.gz) <= 50 ))
    }
@test "validate package for bert-large-bfloat16-inference creates bert-large-bfloat16-inference.tar.gz" {
      run model-builder package bert-large-bfloat16-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ bert-large-bfloat16-inference.tar.gz ]]
      (( $(last_modified output/bert-large-bfloat16-inference.tar.gz) <= 50 ))
    }
@test "validate package for bert-large-fp32-inference creates bert-large-fp32-inference.tar.gz" {
      run model-builder package bert-large-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ bert-large-fp32-inference.tar.gz ]]
      (( $(last_modified output/bert-large-fp32-inference.tar.gz) <= 50 ))
    }
@test "validate package for bert-large-fp32-training creates bert-large-fp32-training.tar.gz" {
      run model-builder package bert-large-fp32-training
      (( $status == 0 ))
      [[ "${lines[@]}" =~ bert-large-fp32-training.tar.gz ]]
      (( $(last_modified output/bert-large-fp32-training.tar.gz) <= 50 ))
    }
@test "validate package for faster-rcnn-fp32-inference creates faster-rcnn-fp32-inference.tar.gz" {
      run model-builder package faster-rcnn-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ faster-rcnn-fp32-inference.tar.gz ]]
      (( $(last_modified output/faster-rcnn-fp32-inference.tar.gz) <= 50 ))
    }
@test "validate package for faster-rcnn-int8-inference creates faster-rcnn-int8-inference.tar.gz" {
      run model-builder package faster-rcnn-int8-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ faster-rcnn-int8-inference.tar.gz ]]
      (( $(last_modified output/faster-rcnn-int8-inference.tar.gz) <= 50 ))
    }
@test "validate package for inceptionv3-fp32-inference creates inceptionv3-fp32-inference.tar.gz" {
      run model-builder package inceptionv3-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ inceptionv3-fp32-inference.tar.gz ]]
      (( $(last_modified output/inceptionv3-fp32-inference.tar.gz) <= 50 ))
    }
@test "validate package for inceptionv3-int8-inference creates inceptionv3-int8-inference.tar.gz" {
      run model-builder package inceptionv3-int8-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ inceptionv3-int8-inference.tar.gz ]]
      (( $(last_modified output/inceptionv3-int8-inference.tar.gz) <= 50 ))
    }
@test "validate package for maskrcnn-fp32-inference creates maskrcnn-fp32-inference.tar.gz" {
      run model-builder package maskrcnn-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ maskrcnn-fp32-inference.tar.gz ]]
      (( $(last_modified output/maskrcnn-fp32-inference.tar.gz) <= 50 ))
    }
@test "validate package for mobilenet-v1-fp32-inference creates mobilenet-v1-fp32-inference.tar.gz" {
      run model-builder package mobilenet-v1-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ mobilenet-v1-fp32-inference.tar.gz ]]
      (( $(last_modified output/mobilenet-v1-fp32-inference.tar.gz) <= 50 ))
    }
@test "validate package for mobilenet-v1-int8-inference creates mobilenet-v1-int8-inference.tar.gz" {
      run model-builder package mobilenet-v1-int8-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ mobilenet-v1-int8-inference.tar.gz ]]
      (( $(last_modified output/mobilenet-v1-int8-inference.tar.gz) <= 50 ))
    }
@test "validate package for ncf-fp32-inference creates ncf-fp32-inference.tar.gz" {
      run model-builder package ncf-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ ncf-fp32-inference.tar.gz ]]
      (( $(last_modified output/ncf-fp32-inference.tar.gz) <= 50 ))
    }
@test "validate package for preprocess-coco-val creates preprocess-coco-val.tar.gz" {
      run model-builder package preprocess-coco-val
      (( $status == 0 ))
      [[ "${lines[@]}" =~ preprocess-coco-val.tar.gz ]]
      (( $(last_modified output/preprocess-coco-val.tar.gz) <= 50 ))
    }
@test "validate package for resnet50-fp32-inference creates resnet50-fp32-inference.tar.gz" {
      run model-builder package resnet50-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ resnet50-fp32-inference.tar.gz ]]
      (( $(last_modified output/resnet50-fp32-inference.tar.gz) <= 50 ))
    }
@test "validate package for resnet50-int8-inference creates resnet50-int8-inference.tar.gz" {
      run model-builder package resnet50-int8-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ resnet50-int8-inference.tar.gz ]]
      (( $(last_modified output/resnet50-int8-inference.tar.gz) <= 50 ))
    }
@test "validate package for resnet50v1-5-bfloat16-inference creates resnet50v1-5-bfloat16-inference.tar.gz" {
      run model-builder package resnet50v1-5-bfloat16-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ resnet50v1-5-bfloat16-inference.tar.gz ]]
      (( $(last_modified output/resnet50v1-5-bfloat16-inference.tar.gz) <= 50 ))
    }
@test "validate package for resnet50v1-5-fp32-inference creates resnet50v1-5-fp32-inference.tar.gz" {
      run model-builder package resnet50v1-5-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ resnet50v1-5-fp32-inference.tar.gz ]]
      (( $(last_modified output/resnet50v1-5-fp32-inference.tar.gz) <= 50 ))
    }
@test "validate package for resnet50v1-5-fp32-training creates resnet50v1-5-fp32-training.tar.gz" {
      run model-builder package resnet50v1-5-fp32-training
      (( $status == 0 ))
      [[ "${lines[@]}" =~ resnet50v1-5-fp32-training.tar.gz ]]
      (( $(last_modified output/resnet50v1-5-fp32-training.tar.gz) <= 50 ))
    }
@test "validate package for resnet50v1-5-int8-inference creates resnet50v1-5-int8-inference.tar.gz" {
      run model-builder package resnet50v1-5-int8-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ resnet50v1-5-int8-inference.tar.gz ]]
      (( $(last_modified output/resnet50v1-5-int8-inference.tar.gz) <= 50 ))
    }
@test "validate package for rfcn-fp32-inference creates rfcn-fp32-inference.tar.gz" {
      run model-builder package rfcn-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ rfcn-fp32-inference.tar.gz ]]
      (( $(last_modified output/rfcn-fp32-inference.tar.gz) <= 50 ))
    }
@test "validate package for ssd-mobilenet-fp32-inference creates ssd-mobilenet-fp32-inference.tar.gz" {
      run model-builder package ssd-mobilenet-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ ssd-mobilenet-fp32-inference.tar.gz ]]
      (( $(last_modified output/ssd-mobilenet-fp32-inference.tar.gz) <= 50 ))
    }
@test "validate package for ssd-resnet34-fp32-inference creates ssd-resnet34-fp32-inference.tar.gz" {
      run model-builder package ssd-resnet34-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ ssd-resnet34-fp32-inference.tar.gz ]]
      (( $(last_modified output/ssd-resnet34-fp32-inference.tar.gz) <= 50 ))
    }
@test "validate package for ssd-resnet34-int8-inference creates ssd-resnet34-int8-inference.tar.gz" {
      run model-builder package ssd-resnet34-int8-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ ssd-resnet34-int8-inference.tar.gz ]]
      (( $(last_modified output/ssd-resnet34-int8-inference.tar.gz) <= 50 ))
    }
@test "validate package for transformer-lt-official-fp32-inference creates transformer-lt-official-fp32-inference.tar.gz" {
      run model-builder package transformer-lt-official-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ transformer-lt-official-fp32-inference.tar.gz ]]
      (( $(last_modified output/transformer-lt-official-fp32-inference.tar.gz) <= 50 ))
    }
@test "validate package for unet-fp32-inference creates unet-fp32-inference.tar.gz" {
      run model-builder package unet-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ unet-fp32-inference.tar.gz ]]
      (( $(last_modified output/3d-unet-fp32-inference.tar.gz output/unet-fp32-inference.tar.gz) <= 50 ))
    }
@test "validate package for wavenet-fp32-inference creates wavenet-fp32-inference.tar.gz" {
      run model-builder package wavenet-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ wavenet-fp32-inference.tar.gz ]]
      (( $(last_modified output/wavenet-fp32-inference.tar.gz) <= 50 ))
    }
@test "validate package for wide-deep-fp32-inference creates wide-deep-fp32-inference.tar.gz" {
      run model-builder package wide-deep-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ wide-deep-fp32-inference.tar.gz ]]
      (( $(last_modified output/wide-deep-fp32-inference.tar.gz) <= 50 ))
    }
@test "validate package for wide-deep-large-ds-fp32-training creates wide-deep-large-ds-fp32-training.tar.gz" {
      run model-builder package wide-deep-large-ds-fp32-training
      (( $status == 0 ))
      [[ "${lines[@]}" =~ wide-deep-large-ds-fp32-training.tar.gz ]]
      (( $(last_modified output/wide-deep-large-ds-fp32-training.tar.gz) <= 50 ))
    }

#
# *** tests for k8s package ***
#

@test "validate package-k8s for bert-large-fp32-training creates bert-large-fp32-training-k8s.tar.gz" {
      run model-builder package-k8s bert-large-fp32-training
      (( $status == 0 ))
      [[ "${lines[@]}" =~ bert-large-fp32-training-k8s.tar.gz ]]
      (( $(last_modified output/bert-large-fp32-training-k8s.tar.gz) <= 50 ))
    }
@test "validate package-k8s for resnet50v1-5-fp32-inference creates resnet50v1-5-fp32-inference-k8s.tar.gz" {
      run model-builder package-k8s resnet50v1-5-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ resnet50v1-5-fp32-inference-k8s.tar.gz ]]
      (( $(last_modified output/resnet50v1-5-fp32-inference-k8s.tar.gz) <= 50 ))
    }
@test "validate package-k8s for resnet50v1-5-fp32-training creates resnet50v1-5-fp32-training-k8s.tar.gz" {
      run model-builder package-k8s resnet50v1-5-fp32-training
      (( $status == 0 ))
      [[ "${lines[@]}" =~ resnet50v1-5-fp32-training-k8s.tar.gz ]]
      (( $(last_modified output/resnet50v1-5-fp32-training-k8s.tar.gz) <= 50 ))
    }
@test "validate package-k8s for rfcn-fp32-inference creates rfcn-fp32-inference-k8s.tar.gz" {
      run model-builder package-k8s rfcn-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ rfcn-fp32-inference-k8s.tar.gz ]]
      (( $(last_modified output/rfcn-fp32-inference-k8s.tar.gz) <= 50 ))
    }
@test "validate package-k8s for wide-deep-large-ds-fp32-training creates wide-deep-large-ds-fp32-training-k8s.tar.gz" {
      run model-builder package-k8s wide-deep-large-ds-fp32-training
      (( $status == 0 ))
      [[ "${lines[@]}" =~ wide-deep-large-ds-fp32-training-k8s.tar.gz ]]
      (( $(last_modified output/wide-deep-large-ds-fp32-training-k8s.tar.gz) <= 50 ))
    }

#
# *** tests for build ***
#

@test "validate build image for 3d-unet-fp32-inference creates model-zoo:1.15.2-image-segmentation-3d-unet-fp32-inference" {
      run model-builder --nocache build 3d-unet-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ 3d-unet-fp32-inference ]]
    }
@test "validate build image for bert-large-bfloat16-inference creates model-zoo:2.3.0-language-modeling-bert-large-bfloat16-inference" {
      run model-builder --nocache build bert-large-bfloat16-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ bert-large-bfloat16-inference ]]
    }
@test "validate build image for bert-large-fp32-inference creates model-zoo:2.3.0-language-modeling-bert-large-fp32-inference" {
      run model-builder --nocache build bert-large-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ bert-large-fp32-inference ]]
    }
@test "validate build image for bert-large-fp32-training creates model-zoo:2.3.0-language-modeling-bert-large-fp32-training" {
      run model-builder --nocache build bert-large-fp32-training
      (( $status == 0 ))
      [[ "${lines[@]}" =~ bert-large-fp32-training ]]
    }
@test "validate build image for faster-rcnn-fp32-inference creates model-zoo:1.15.2-object-detection-faster-rcnn-fp32-inference" {
      run model-builder --nocache build faster-rcnn-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ faster-rcnn-fp32-inference ]]
    }
@test "validate build image for faster-rcnn-int8-inference creates model-zoo:1.15.2-object-detection-faster-rcnn-int8-inference" {
      run model-builder --nocache build faster-rcnn-int8-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ faster-rcnn-int8-inference ]]
    }
@test "validate build image for inceptionv3-fp32-inference creates model-zoo:2.3.0-image-recognition-inceptionv3-fp32-inference" {
      run model-builder --nocache build inceptionv3-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ inceptionv3-fp32-inference ]]
    }
@test "validate build image for inceptionv3-int8-inference creates model-zoo:2.3.0-image-recognition-inceptionv3-int8-inference" {
      run model-builder --nocache build inceptionv3-int8-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ inceptionv3-int8-inference ]]
    }
@test "validate build image for maskrcnn-fp32-inference creates model-zoo:1.15.2-image-segmentation-maskrcnn-fp32-inference" {
      run model-builder --nocache build maskrcnn-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ maskrcnn-fp32-inference ]]
    }
@test "validate build image for mobilenet-v1-fp32-inference creates model-zoo:2.3.0-image-recognition-mobilenet-v1-fp32-inference" {
      run model-builder --nocache build mobilenet-v1-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ mobilenet-v1-fp32-inference ]]
    }
@test "validate build image for mobilenet-v1-int8-inference creates model-zoo:2.3.0-image-recognition-mobilenet-v1-int8-inference" {
      run model-builder --nocache build mobilenet-v1-int8-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ mobilenet-v1-int8-inference ]]
    }
@test "validate build image for ncf-fp32-inference creates model-zoo:1.15.2-recommendation-ncf-fp32-inference" {
      run model-builder --nocache build ncf-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ ncf-fp32-inference ]]
    }
@test "validate build image for object-detection creates model-zoo:2.3.0-object-detection" {
      run model-builder --nocache build object-detection
      (( $status == 0 ))
      [[ "${lines[@]}" =~ object-detection ]]
    }
@test "validate build image for preprocess-coco-val creates model-zoo:1.15.2-object-detection-preprocess-coco-val" {
      run model-builder --nocache build preprocess-coco-val
      (( $status == 0 ))
      [[ "${lines[@]}" =~ preprocess-coco-val ]]
    }
@test "validate build image for resnet50-fp32-inference creates model-zoo:2.3.0-image-recognition-resnet50-fp32-inference" {
      run model-builder --nocache build resnet50-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ resnet50-fp32-inference ]]
    }
@test "validate build image for resnet50-int8-inference creates model-zoo:2.3.0-image-recognition-resnet50-int8-inference" {
      run model-builder --nocache build resnet50-int8-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ resnet50-int8-inference ]]
    }
@test "validate build image for resnet50v1-5-bfloat16-inference creates model-zoo:2.3.0-image-recognition-resnet50v1-5-bfloat16-inference" {
      run model-builder --nocache build resnet50v1-5-bfloat16-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ resnet50v1-5-bfloat16-inference ]]
    }
@test "validate build image for resnet50v1-5-fp32-inference creates model-zoo:2.3.0-image-recognition-resnet50v1-5-fp32-inference" {
      run model-builder --nocache build resnet50v1-5-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ resnet50v1-5-fp32-inference ]]
    }
@test "validate build image for resnet50v1-5-fp32-training creates model-zoo:2.3.0-image-recognition-resnet50v1-5-fp32-training" {
      run model-builder --nocache build resnet50v1-5-fp32-training
      (( $status == 0 ))
      [[ "${lines[@]}" =~ resnet50v1-5-fp32-training ]]
    }
@test "validate build image for resnet50v1-5-int8-inference creates model-zoo:2.3.0-image-recognition-resnet50v1-5-int8-inference" {
      run model-builder --nocache build resnet50v1-5-int8-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ resnet50v1-5-int8-inference ]]
    }
@test "validate build image for rfcn-fp32-inference creates model-zoo:2.3.0-object-detection-rfcn-fp32-inference" {
      run model-builder --nocache build rfcn-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ rfcn-fp32-inference ]]
    }
@test "validate build image for ssd-mobilenet-fp32-inference creates model-zoo:2.3.0-object-detection-ssd-mobilenet-fp32-inference" {
      run model-builder --nocache build ssd-mobilenet-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ ssd-mobilenet-fp32-inference ]]
    }
@test "validate build image for ssd-resnet34-fp32-inference creates model-zoo:2.3.0-object-detection-ssd-resnet34-fp32-inference" {
      run model-builder --nocache build ssd-resnet34-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ ssd-resnet34-fp32-inference ]]
    }
@test "validate build image for ssd-resnet34-int8-inference creates model-zoo:2.3.0-object-detection-ssd-resnet34-int8-inference" {
      run model-builder --nocache build ssd-resnet34-int8-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ ssd-resnet34-int8-inference ]]
    }
@test "validate build image for transformer-lt-official-fp32-inference creates model-zoo:2.3.0-language-translation-transformer-lt-official-fp32-inference" {
      run model-builder --nocache build transformer-lt-official-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ transformer-lt-official-fp32-inference ]]
    }
@test "validate build image for unet-fp32-inference creates model-zoo:1.15.2-image-segmentation-3d-unet-fp32-inference model-zoo:1.15.2-image-segmentation-unet-fp32-inference" {
      run model-builder --nocache build unet-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ unet-fp32-inference ]]
    }
@test "validate build image for wavenet-fp32-inference creates model-zoo:1.15.2-text-to-speech-wavenet-fp32-inference" {
      run model-builder --nocache build wavenet-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ wavenet-fp32-inference ]]
    }
@test "validate build image for wide-deep-fp32-inference creates model-zoo:2.3.0-recommendation-wide-deep-fp32-inference" {
      run model-builder --nocache build wide-deep-fp32-inference
      (( $status == 0 ))
      [[ "${lines[@]}" =~ wide-deep-fp32-inference ]]
    }
@test "validate build image for wide-deep-large-ds-fp32-training creates model-zoo:2.3.0-recommendation-wide-deep-large-ds-fp32-training" {
      run model-builder --nocache build wide-deep-large-ds-fp32-training
      (( $status == 0 ))
      [[ "${lines[@]}" =~ wide-deep-large-ds-fp32-training ]]
    }
@test "validate build image for scikit-learn creates model-zoo:scikit-learn" {
      run model-builder --nocache build -r ml scikit-learn
      (( $status == 0 ))
      [[ "${lines[@]}" =~ scikit-learn ]]
    }
@test "validate build image for scikit-learn-census creates model-zoo:scikit-learn-census" {
      run model-builder --nocache build -r ml scikit-learn-census
      (( $status == 0 ))
      [[ "${lines[@]}" =~ scikit-learn-census ]]
    }
@test "validate build image for xgboost creates model-zoo:xgboost" {
      run model-builder --nocache build -r ml xgboost
      (( $status == 0 ))
      [[ "${lines[@]}" =~ xgboost ]]
    }
