apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  name: wide-deep-large-ds-fp32-train-serve-wf # {"$openapi":"WORKFLOW_NAME"}
spec:
  entrypoint: wide-deep-large-ds-fp32-training # {"$openapi":"MODEL_NAME"}
  arguments:
    parameters:
    - name: DEPLOYMENT_NAME
      value: wide-deep-large-ds-fp32-training-deployment # {"$openapi":"DEPLOYMENT_NAME"}
    - name: SERVER_NAME
      value: wide-deep-large-ds-fp32-training-server # {"$openapi":"SERVER_NAME"}
    - name: SERVICE_NAME
      value: wide-deep-large-ds-fp32-training-service # {"$openapi":"SERVICE_NAME"}
    - name: USER_ID
      value: "0" # {"$openapi":"USER_ID_VALUE"}
    - name: GROUP_ID
      value: "0" # {"$openapi":"GROUP_ID_VALUE"}
    - name: FS_ID
      value: "0" # {"$openapi":"FS_ID_VALUE"}
    - name: NFS_PATH
      value: /nfs # {"$openapi":"NFS_PATH"}
    - name: NFS_SERVER
      value: 0.0.0.0 # {"$openapi":"NFS_SERVER"}
    - name: OUTPUT_DIR
      value: /nfs/root/wide-deep-large-ds-fp32-training/output # {"$openapi":"OUTPUT_PATH"}
    - name: REPLICAS
      value: "3" # {"$openapi":"REPLICAS_VALUE"}
    - name: TF_SERVING_PORT
      value: "8501" # {"$openapi":"TF_SERVING_PORT_VALUE"}
  templates:
  - name: wide-deep-large-ds-fp32-training # {"$openapi":"MODEL_NAME"}
    steps:
    - - name: train-wide-deep-large-ds
        template: train-wide-deep-large-ds
    - - name: wide-deep-large-ds-deployment
        template: wide-deep-large-ds-deployment
    - - name: wide-deep-large-ds-service
        template: wide-deep-large-ds-service
  - name: train-wide-deep-large-ds
    securityContext:
      runAsUser: 0 # {"$openapi":"USER_ID"}
      runAsGroup: 0 # {"$openapi":"GROUP_ID"}
      fsGroup: 0 # {"$openapi":"FS_ID"}
    container:
      image: docker.io/model-zoo:2.3.0-recommendation-wide-deep-large-ds-fp32-training # {"$openapi":"IMAGE"}
      imagePullPolicy: Always
      workingDir: /workspace/wide-deep-large-ds-fp32-training # {"$openapi":"MODEL_DIR"}
      command: # {"$openapi":"MODEL_COMMAND"}
      - /workspace/wide-deep-large-ds-fp32-training/quickstart/fp32_training_check_accuracy.sh # {"$openapi":"MODEL_COMMAND"}
      env:
      - name: CHECKPOINT_DIR
        value: /nfs/root/wide-deep-large-ds-fp32-training/checkpoints # {"$openapi":"CHECKPOINT_PATH"}
      - name: DATASET_DIR
        value: /datasets # {"$openapi":"DATASET_DIR"}
      - name: GROUP_ID
        value: "0" # {"$openapi":"GROUP_ID_VALUE"}
      - name: GROUP_NAME
        value: root # {"$openapi":"GROUP_NAME"}
      - name: OUTPUT_DIR # Serving requires a model base directory and a model name folder, so
        value: /nfs/root/wide-deep-large-ds-fp32-training/output # {"$openapi":"OUTPUT_PATH"}
      - name: TARGET_ACCURACY
        value: "0.75" # {"$openapi":"TARGET_ACCURACY_VALUE"}
      - name: USER_ID
        value: "0" # {"$openapi":"USER_ID_VALUE"}
      - name: USER_NAME
        value: root # {"$openapi":"USER_NAME"}
      volumeMounts:
      - name: datasets
        mountPath: /datasets # {"$openapi":"DATASET_DIR"}
        readOnly: true
      - name: nfs-path
        mountPath: /nfs # {"$openapi":"NFS_PATH"}
      - name: mlops-scripts
        mountPath: /workspace/wide-deep-large-ds-fp32-training/quickstart/fp32_training_check_accuracy.sh # {"$openapi":"MODEL_COMMAND"}
        subPath: fp32_training_check_accuracy.sh # {"$openapi":"MODEL_SCRIPT"}
    retryStrategy:
      limit: 10 # {"$openapi":"RETRY_LIMIT"}
      retryPolicy: "OnFailure"
    volumes:
    - name: datasets
      hostPath:
        path: /datasets # {"$openapi":"DATASET_DIR"}
    - name: nfs-path
      nfs:
        server: 0.0.0.0 # {"$openapi":"NFS_SERVER"}
        path: /nfs # {"$openapi":"NFS_PATH"}
    - name: mlops-scripts
      configMap:
        name: mlops-scripts-wide-deep-large-ds-fp32-training
        defaultMode: 0770
        items:
        - key: fp32_training_check_accuracy.sh # {"$openapi":"MODEL_SCRIPT"}
          path: fp32_training_check_accuracy.sh # {"$openapi":"MODEL_SCRIPT"}
  - name: wide-deep-large-ds-deployment
    resource:
      action: create
      manifest: |
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: {{workflow.parameters.DEPLOYMENT_NAME}}
          ownerReferences:
          - apiVersion: argoproj.io/v1alpha1
            kind: Workflow
            blockOwnerDeletion: true
            name: "{{workflow.name}}"
            uid: "{{workflow.uid}}"
        spec:
          selector:
            matchLabels:
              app: {{workflow.parameters.SERVER_NAME}}
          replicas: {{workflow.parameters.REPLICAS}}
          template:
            metadata:
              labels:
                app: {{workflow.parameters.SERVER_NAME}}
            spec:
              securityContext:
                runAsUser: {{workflow.parameters.USER_ID}}
                runAsGroup: {{workflow.parameters.GROUP_ID}}
                fsGroup: {{workflow.parameters.FS_ID}}
              containers:
              - name: {{workflow.parameters.SERVER_NAME}}
                image: intel/intel-optimized-tensorflow-serving:2.3.0
                env:
                - name: MODEL_BASE_PATH
                  value: {{workflow.parameters.OUTPUT_DIR}}
                - name: TF_CPP_MIN_VLOG_LEVEL
                  value: "1"
                volumeMounts:
                - name: nfs-path
                  mountPath: {{workflow.parameters.NFS_PATH}}
                ports:
                - containerPort: {{workflow.parameters.TF_SERVING_PORT}}
              volumes:
              - name: nfs-path
                nfs:
                  server: {{workflow.parameters.NFS_SERVER}}
                  path: {{workflow.parameters.NFS_PATH}}
  - name: wide-deep-large-ds-service
    resource:
      action: create
      manifest: |
        apiVersion: v1
        kind: Service
        metadata:
          name: {{workflow.parameters.SERVICE_NAME}}
          labels:
            app: {{workflow.parameters.SERVER_NAME}}
          ownerReferences:
          - apiVersion: argoproj.io/v1alpha1
            kind: Workflow
            blockOwnerDeletion: true
            name: "{{workflow.name}}"
            uid: "{{workflow.uid}}"
        spec:
          # comment or delete the following line if you want to use a LoadBalancer
          type: NodePort
          # if your cluster supports it, uncomment the following to automatically create
          # an external load-balanced IP for the frontend service.
          # type: LoadBalancer
          ports:
          - protocol: TCP
            port: 8501
            targetPort: 8500
          selector:
            app: {{workflow.parameters.SERVER_NAME}}
