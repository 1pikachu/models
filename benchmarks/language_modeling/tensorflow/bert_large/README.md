# BERT

> If you are running using AI Kit, first follow the
> [instructions here](/docs/general/tensorflow/AIKit.md) to get your environment setup.

The following documents have instructions for running BERT large:
* [BFloat16 Inference](/benchmarks/language_modeling/tensorflow/bert_large/inference/bfloat16/README.md)
* [FP32 Inference](/benchmarks/language_modeling/tensorflow/bert_large/inference/fp32/README.md)
* [Int8 Inference](/benchmarks/language_modeling/tensorflow/bert_large/inference/int8/README.md)
* [BFloat16 Training](/benchmarks/language_modeling/tensorflow/bert_large/training/bfloat16/README.md)
* [FP32 Training](/benchmarks/language_modeling/tensorflow/bert_large/training/fp32/README.md)
